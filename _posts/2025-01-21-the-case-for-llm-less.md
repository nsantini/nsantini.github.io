---
layout: post
title: The case for LLM-less
date: 2025-01-21 13:29 +1300
---

GenAI's underlying technology, Large Language Models, or LLMs for short, have taken the world by storm. It would seem that everybody is using them. And every product is incorporating them. And if you are not, you are missing out. Or so it seems.

As with every new piece of technology, specially highly hyped ones, there is a risk of jumping into the bandwagon without much thinking. We run the risk of believing that they are a silver bullet that we can apply to every problem. This leaves us vulnerable to blind spots that can hurt us, while thinking we are being helped.

Like with any tool, it's important to understand when, where, and how to use them. It can add value if used properly. But it can cause more harm than good when misused.

There is a point to be made about writing. [Paul Graham wrote](https://paulgraham.com/writes.html) "To write well you have to think clearly, and thinking clearly is hard.". And this is a very interesting observation with an important corollary. When we offload our writing to an LLM, we skip the thinking that goes with it.

But why is this important? Well, if you are not thinking about what you are writing, then you are not understanding it. And this can be very problematic, specially if what you are writing to guide your work, as well as others.

Consider the situation where you are writing information for work to be done by your team. You want to be specific, succinct, and accurate. The output of LLMs tend to be more generic, verbose, and repetitive. Even worse, it often suffers from what we call "hallucinations", which can cause a lot of issues due to their (sometimes hard to detect) incorrectness.

Like I said earlier, it's very import to understand when, where, and how to use this technology. So let's look into that.

But first, a disclaimer: I have made a point of not using GenAI to write the posts on my blog. They are a way for me to think about, and process my experiences. To clarify my thinking and learn. However, I do use LLMs in other contexts, and I hope that sharing my experience with them can help others.

One area of my professional life where I'm using LLMs is coding. I have taken on the VS Code fork Cursor as my default IDE. Its integrations with LLMs have helped me do away with parts of coding that were menial and unappealing. But, it works well because I know what I'm trying to do. And I'm able to identify when things are not the way they need to be. I put my 20+ years of experience behind it to make it work for me. It's not something I would recommend to someone who is starting their career. At least not as the only way to do coding.

The other use cased for GenAI I make, is to help me draft documents, or part of them. It can work as a way to bounce ideas and work through them. The outcome is a good enough draft that I then edit and change to make it fit for purpose. But, it's a draft, not the final product. And this is an important distinction to make.

And that is it. My thoughts and experiences, and hopefully case for, using less GenAI (LLMs). Or at least be more critical about when, were, and how we use this new technology.
